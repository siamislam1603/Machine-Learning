{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `Scratch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[1,2,3,2.5]\n",
    "weights=[[0.2,0.8,-0.5,1.0],\n",
    "        [.5,-.91,.26,-.5],\n",
    "        [-.26,-.27,.17,.87]]\n",
    "biases=[2,3,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer output:[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "layer_output=[]\n",
    "for neuron_weights,neuron_bias in zip(weights,biases):\n",
    "    neuron_output=0\n",
    "    for n_input,weight in zip(inputs,neuron_weights):\n",
    "        neuron_output+=n_input*weight\n",
    "    neuron_output+=neuron_bias\n",
    "    layer_output.append(neuron_output)\n",
    "print(f\"Layer output:{layer_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `dot` product for-\n",
    "\n",
    "* Single sample of input features (Vector)\n",
    "\n",
    "[1 , 2].[3 , 2]=[1x3 , 2x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.8  , -1.79 ,  1.885])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_weights_dot_inputs=np.dot(weights,inputs)\n",
    "sum_of_weights_dot_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 0.5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8  , 1.21 , 2.385])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output=sum_of_weights_dot_inputs+biases\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `dot` product for-\n",
    "\n",
    "* Batch of samples (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8  , -1.79 ,  1.885],\n",
       "       [ 6.9  , -4.81 , -0.3  ],\n",
       "       [-0.59 , -1.949, -0.474]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=[[1,2,3,2.5],\n",
    "       [2,5,-1,2],\n",
    "       [-1.5,2.7,3.3,-.8]]\n",
    "\n",
    "weights=[[0.2,0.8,-0.5,1.0],\n",
    "        [.5,-.91,.26,-.5],\n",
    "        [-.26,-.27,.17,.87]]\n",
    "\n",
    "biases=[2,3,0.5]\n",
    "\n",
    "dot_product=np.dot(inputs,np.array(weights).T) #inputs(3,4)*weights(3,4).T\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.8  ,  1.21 ,  2.385],\n",
       "       [ 8.9  , -1.81 ,  0.2  ],\n",
       "       [ 1.41 ,  1.051,  0.026]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output=dot_product+biases\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X=[[1,2,3,2.5],\n",
    "   [2,5,-1,2],\n",
    "   [-1.5,2.7,3.3,-.8]]\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=0.1*np.random.randn(n_inputs,n_neurons) # n_inputs x n_neurons matrix points center around 0\n",
    "        self.biases=np.zeros((1,n_neurons)) #rows=1,cols=n_neurons in tuples\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.dot(inputs,self.weights)+self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer1:\n",
      "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
      " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
      " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n",
      "\n",
      "Layer2:\n",
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "layer1=Layer_Dense(4,5)\n",
    "layer1.forward(X)\n",
    "print(f\"Layer1:\\n{layer1.output}\")\n",
    "\n",
    "layer2=Layer_Dense(5,2)\n",
    "layer2.forward(layer1.output)\n",
    "print(f\"\\nLayer2:\\n{layer2.output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer1:\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-8.35815910e-04 -7.90404272e-04 -1.33452227e-03  4.65504505e-04\n",
      "   4.56846210e-05]\n",
      " [-2.39994470e-03  5.93469958e-05 -2.24808278e-03  2.03573116e-04\n",
      "   6.10024377e-04]\n",
      " ...\n",
      " [ 1.13291524e-01 -1.89262271e-01 -2.06855070e-02  8.11079666e-02\n",
      "  -6.71350807e-02]\n",
      " [ 1.34588361e-01 -1.43197834e-01  3.09493970e-02  5.66337556e-02\n",
      "  -6.29687458e-02]\n",
      " [ 1.07817926e-01 -2.00809643e-01 -3.37579325e-02  8.72561932e-02\n",
      "  -6.81458861e-02]]\n",
      "\n",
      "Hidden layer activation:\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65504505e-04\n",
      "  4.56846210e-05]\n",
      " [0.00000000e+00 5.93469958e-05 0.00000000e+00 2.03573116e-04\n",
      "  6.10024377e-04]\n",
      " ...\n",
      " [1.13291524e-01 0.00000000e+00 0.00000000e+00 8.11079666e-02\n",
      "  0.00000000e+00]\n",
      " [1.34588361e-01 0.00000000e+00 3.09493970e-02 5.66337556e-02\n",
      "  0.00000000e+00]\n",
      " [1.07817926e-01 0.00000000e+00 0.00000000e+00 8.72561932e-02\n",
      "  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "X,y=spiral_data(100,3)\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=0.1*np.random.randn(n_inputs,n_neurons) # n_inputs x n_neurons matrix points center around 0\n",
    "        self.biases=np.zeros((1,n_neurons)) #rows=1,cols=n_neurons in tuples\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.dot(inputs,self.weights)+self.biases\n",
    "        \n",
    "class Activation_ReLU:\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.maximum(0,inputs) # negative i/p becomes 0 & to get non-zero as o/p we need to make biases non-zero\n",
    "\n",
    "layer1=Layer_Dense(2,5)\n",
    "layer1.forward(X)\n",
    "print(f\"Layer1:\\n{layer1.output}\")\n",
    "\n",
    "activation1=Activation_ReLU()\n",
    "activation1.forward(layer1.output)\n",
    "print(f\"\\nHidden layer activation:\\n{activation1.output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
